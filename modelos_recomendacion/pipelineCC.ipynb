{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78a06f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import mlflow\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "ruta_actual = os.getcwd()\n",
    "mlflow.set_tracking_uri(f\"file:///{ruta_actual}/mlruns\")\n",
    "mlflow.set_experiment(\"Modelos de Recomendaci√≥n - Comparativa\")\n",
    "\n",
    "# Cargamos cada archivo CSV en un DataFrame de pandas para poder manipularlos como tablas de datos\n",
    "df_events = pd.read_csv(\"../databases/events.csv\")\n",
    "df_order_items = pd.read_csv(\"../databases/order_items.csv\")\n",
    "df_orders = pd.read_csv(\"../databases/orders.csv\")\n",
    "df_products = pd.read_csv(\"../databases/products.csv\")\n",
    "df_reviews = pd.read_csv(\"../databases/reviews.csv\")\n",
    "df_users = pd.read_csv(\"../databases/users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c6375ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos listos. Ordenes de entrenamiento: 16000 | Ordenes de prueba: 4000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Se organiza los productos por ordenes\n",
    "df_interacciones = df_order_items[['order_id', 'product_id']].copy()\n",
    "\n",
    "# Se divide 80 train / 20 test\n",
    "# Es mejor dividir por order_id para no separar una misma orden en dos\n",
    "ordenes_unicas = df_interacciones['order_id'].unique()\n",
    "train_ids, test_ids = train_test_split(ordenes_unicas, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = df_interacciones[df_interacciones['order_id'].isin(train_ids)]\n",
    "test_data = df_interacciones[df_interacciones['order_id'].isin(test_ids)]\n",
    "\n",
    "print(f\"‚úÖ Datos listos. Ordenes de entrenamiento: {len(train_ids)} | Ordenes de prueba: {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49b386ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando pares de productos... (esto puede tardar unos segundos)\n",
      "‚úÖ Matriz creada. Se encontraron 79118 relaciones √∫nicas entre productos.\n"
     ]
    }
   ],
   "source": [
    "# Unimos la tabla consigo misma usando order_id para encontrar parejas\n",
    "print(\"Generando pares de productos... (esto puede tardar unos segundos)\")\n",
    "df_pares = pd.merge(train_data, train_data, on='order_id')\n",
    "\n",
    "# Filtramos para no contar un producto consigo mismo (ej: leche con leche)\n",
    "df_pares = df_pares[df_pares['product_id_x'] != df_pares['product_id_y']]\n",
    "\n",
    "# Contamos la frecuencia de cada pareja\n",
    "matriz_cooc = df_pares.groupby(['product_id_x', 'product_id_y']).size().reset_index(name='frecuencia')\n",
    "\n",
    "# Ordenamos por los m√°s frecuentes para facilitar la b√∫squeda\n",
    "matriz_cooc = matriz_cooc.sort_values(['product_id_x', 'frecuencia'], ascending=[True, False])\n",
    "\n",
    "print(f\"‚úÖ Matriz creada. Se encontraron {len(matriz_cooc)} relaciones √∫nicas entre productos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a7a6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_cc_eval(product_id, df_matriz, df_products, top_n=3):\n",
    "    # categoria del producto seleccionado\n",
    "    row = df_products[df_products['product_id'] == product_id]\n",
    "    if row.empty:\n",
    "        return []\n",
    "\n",
    "    cat_seed = row.iloc[0]['Category']\n",
    "\n",
    "    candidatos = df_matriz[df_matriz['product_id_x'] == product_id]\n",
    "    if candidatos.empty:\n",
    "        return []\n",
    "\n",
    "    recs = candidatos.merge(\n",
    "        df_products[['product_id', 'Category']],\n",
    "        left_on='product_id_y',\n",
    "        right_on='product_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    recs = recs[\n",
    "        (recs['Category'] == cat_seed) &\n",
    "        (recs['product_id_y'] != product_id)\n",
    "    ]\n",
    "\n",
    "    return recs['product_id_y'].head(top_n).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b2bc310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_cc_eval(product_id, df_matriz, df_products, top_n=3):\n",
    "    # Producto semilla\n",
    "    row = df_products[df_products['product_id'] == product_id]\n",
    "    if row.empty:\n",
    "        return []\n",
    "    cat_seed = row.iloc[0]['Category']\n",
    "    subcat_seed = row.iloc[0]['SubCategory']\n",
    "    candidatos = df_matriz[df_matriz['product_id_x'] == product_id]\n",
    "    if candidatos.empty:\n",
    "        return []\n",
    "    recs = candidatos.merge(\n",
    "        df_products[['product_id', 'Category', 'SubCategory']],\n",
    "        left_on='product_id_y',\n",
    "        right_on='product_id',\n",
    "        how='left'\n",
    "    )\n",
    "    recs = recs[recs['product_id_y'] != product_id]\n",
    "    recs = recs.sort_values('frecuencia', ascending=False)\n",
    "    recomendaciones = []\n",
    "    nivel_1 = (\n",
    "        recs[\n",
    "            (recs['Category'] == cat_seed) &\n",
    "            (recs['SubCategory'] == subcat_seed)\n",
    "        ]\n",
    "        .drop_duplicates(subset='product_id_y')\n",
    "    )\n",
    "    recomendaciones.extend(nivel_1['product_id_y'].tolist())\n",
    "\n",
    "    if len(recomendaciones) < top_n:\n",
    "        nivel_2 = (\n",
    "            recs[\n",
    "                (recs['Category'] == cat_seed) &\n",
    "                (recs['SubCategory'] != subcat_seed)\n",
    "            ]\n",
    "            .drop_duplicates(subset='product_id_y')\n",
    "        )\n",
    "        nivel_2 = nivel_2[\n",
    "            ~nivel_2['product_id_y'].isin(recomendaciones)\n",
    "        ]\n",
    "        faltantes = top_n - len(recomendaciones)\n",
    "        recomendaciones.extend(\n",
    "            nivel_2['product_id_y'].head(faltantes).tolist()\n",
    "        )\n",
    "    if len(recomendaciones) < top_n:\n",
    "        nivel_3 = (\n",
    "            recs[\n",
    "                recs['Category'] != cat_seed\n",
    "            ]\n",
    "            .drop_duplicates(subset='product_id_y')\n",
    "        )\n",
    "        nivel_3 = nivel_3[\n",
    "            ~nivel_3['product_id_y'].isin(recomendaciones)\n",
    "        ]\n",
    "        faltantes = top_n - len(recomendaciones)\n",
    "        recomendaciones.extend(\n",
    "            nivel_3['product_id_y'].head(faltantes).tolist()\n",
    "        )\n",
    "    return recomendaciones[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7943a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModeloCoocurrencia:\n",
    "#     def __init__(self, df_matriz, df_products):\n",
    "#         self.df_matriz = df_matriz\n",
    "#         self.df_products = df_products\n",
    "\n",
    "#     def recomendar(self, product_id, top_n=3):\n",
    "#         return recomendar_cc_eval(\n",
    "#             product_id,\n",
    "#             self.df_matriz,\n",
    "#             self.df_products,\n",
    "#             top_n\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1aaba93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Definir la l√≥gica de rutas (Id√©ntica a la que ya usas)\n",
    "# ruta_actual = os.getcwd()\n",
    "\n",
    "# if os.path.exists(os.path.join(ruta_actual, \"modelos_entrenados\")):\n",
    "#     ruta_modelos = os.path.join(ruta_actual, \"modelos_entrenados\")\n",
    "# else:\n",
    "#     ruta_modelos = os.path.join(os.path.dirname(ruta_actual), \"modelos_entrenados\")\n",
    "\n",
    "# if not os.path.exists(ruta_modelos):\n",
    "#     os.makedirs(ruta_modelos)\n",
    "\n",
    "# # 2. Nombre del archivo para el modelo CC\n",
    "# archivo_salida_cc = os.path.join(ruta_modelos, \"modelo_recomendacion_cc.pkl\")\n",
    "\n",
    "# # 3. Guardar AMBOS DataFrames en un solo archivo\n",
    "# # Los guardamos como una tupla: (matriz, productos)\n",
    "# modelo_cc = ModeloCoocurrencia(matriz_cooc, df_products)\n",
    "\n",
    "# with open(archivo_salida_cc, 'wb') as f:\n",
    "#     pickle.dump(modelo_cc, f)\n",
    "\n",
    "\n",
    "# print(f\"üíæ Modelo CC guardado exitosamente en:\\n{archivo_salida_cc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "334b7aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_coocurrencia(df_test, df_matriz, df_products, k):\n",
    "    ordenes = df_test.groupby('order_id')['product_id'].apply(list)\n",
    "\n",
    "    precisions, recalls = [], []\n",
    "    mrrs, maps, ndcgs = [], [], []\n",
    "\n",
    "    for items in ordenes:\n",
    "        if len(items) < 2:\n",
    "            continue\n",
    "\n",
    "        for i in range(len(items)):\n",
    "            seed = items[i]\n",
    "            objetivos = set(items[:i] + items[i+1:])\n",
    "\n",
    "            preds = recomendar_cc_eval(seed, df_matriz, df_products, k)\n",
    "            if len(preds) == 0:\n",
    "                continue\n",
    "\n",
    "            hits = [1 if p in objetivos else 0 for p in preds]\n",
    "            aciertos = sum(hits)\n",
    "\n",
    "            # Precision / Recall\n",
    "            precisions.append(aciertos / k)\n",
    "            recalls.append(aciertos / len(objetivos))\n",
    "\n",
    "            # MRR\n",
    "            rr = 0\n",
    "            for r, p in enumerate(preds, 1):\n",
    "                if p in objetivos:\n",
    "                    rr = 1 / r\n",
    "                    break\n",
    "            mrrs.append(rr)\n",
    "\n",
    "            # MAP\n",
    "            ap, h = 0, 0\n",
    "            for idx, p in enumerate(preds):\n",
    "                if p in objetivos:\n",
    "                    h += 1\n",
    "                    ap += h / (idx + 1)\n",
    "            maps.append(ap / min(len(objetivos), k))\n",
    "\n",
    "            # NDCG\n",
    "            dcg, idcg = 0, 0\n",
    "            for idx, p in enumerate(preds):\n",
    "                if p in objetivos:\n",
    "                    dcg += 1 / np.log2(idx + 2)\n",
    "            for idx in range(min(len(objetivos), k)):\n",
    "                idcg += 1 / np.log2(idx + 2)\n",
    "            ndcgs.append(dcg / idcg if idcg > 0 else 0)\n",
    "\n",
    "    if len(precisions) == 0:\n",
    "        print(\"‚ö†Ô∏è No se generaron predicciones evaluables\")\n",
    "        return None\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"üìä REPORTE FINAL CO-OCURRENCIA (K={k})\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Precision       | {np.mean(precisions):.4f}\")\n",
    "    print(f\"Recall          | {np.mean(recalls):.4f}\")\n",
    "    print(f\"F1-Score        | {(2*np.mean(precisions)*np.mean(recalls)/(np.mean(precisions)+np.mean(recalls)+1e-9)):.4f}\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"MRR             | {np.mean(mrrs):.4f}\")\n",
    "    print(f\"MAP             | {np.mean(maps):.4f}\")\n",
    "    print(f\"NDCG            | {np.mean(ndcgs):.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    name = f\"CC_K{k}\"\n",
    "    with mlflow.start_run(run_name=name):\n",
    "\n",
    "        # --- Par√°metros ---\n",
    "        mlflow.log_param(\"modelo\", \"CC\")\n",
    "        mlflow.log_param(\"k\", k)\n",
    "\n",
    "        # --- M√©tricas ---\n",
    "        mlflow.log_metric(\"precision\", np.mean(precisions))\n",
    "        mlflow.log_metric(\"recall\", np.mean(recalls))\n",
    "        mlflow.log_metric(\"f1\", (2*np.mean(precisions)*np.mean(recalls)/(np.mean(precisions)+np.mean(recalls)+1e-9)))\n",
    "        mlflow.log_metric(\"mrr\", np.mean(mrrs))\n",
    "        mlflow.log_metric(\"map\", np.mean(maps))\n",
    "        mlflow.log_metric(\"ndcg\", np.mean(ndcgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "75d7446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üìä REPORTE FINAL CO-OCURRENCIA (K=5)\n",
      "==================================================\n",
      "Precision       | 0.0873\n",
      "Recall          | 0.2176\n",
      "F1-Score        | 0.1246\n",
      "--------------------------------------------------\n",
      "MRR             | 0.2406\n",
      "MAP             | 0.1678\n",
      "NDCG            | 0.1993\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "evaluar_coocurrencia(\n",
    "    test_data,\n",
    "    matriz_cooc,\n",
    "    df_products,\n",
    "    k=5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
