{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9db57ff",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "# **Proyecto Final Data Science**\n",
    "## **Modelo de asociaciÃ³n**\n",
    "\n",
    "Equipo: 2 - Quantum Insights\n",
    "Integrantes:\n",
    "- Felipe Varela - Product Owner\n",
    "- Freddy Yaquive - Data Scientist\n",
    "- Ivan Martinez - Data Scientist\n",
    "- Sebastian Moya - Data Scientist\n",
    "- NicolÃ¡s Lazarte - Scrum Master\n",
    "\n",
    "Cohorte: DSFT01\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5020f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import mlflow\n",
    "import os\n",
    "import pickle \n",
    "\n",
    "ruta_actual = os.getcwd()\n",
    "mlflow.set_tracking_uri(f\"file:///{ruta_actual}/mlruns\")\n",
    "mlflow.set_experiment(\"Modelos de RecomendaciÃ³n - Comparativa\")\n",
    "\n",
    "df_order_items = pd.read_csv(\"../databases/order_items.csv\")\n",
    "df_orders = pd.read_csv(\"../databases/orders.csv\")\n",
    "df_products = pd.read_csv(\"../databases/products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9202848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order_items = df_order_items.drop(columns=\"Unnamed: 0\",axis=1)\n",
    "df_orders = df_orders.drop(columns=\"Unnamed: 0\",axis=1)\n",
    "df_products = df_products.drop(columns=\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2293f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se junta las tablas orders y order_items, para su entrenamiento de asociacion \n",
    "df_orders_final = df_order_items.merge(df_orders, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dab42b",
   "metadata": {},
   "source": [
    "### Transformacion de tablas para 0 y 1, filas = usuarios, columnas = productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb6b3edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros totales: 64359\n",
      "Registros para entrenamiento: 51487\n",
      "Registros para evaluaciÃ³n: 12872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividimos las interacciones originales\n",
    "train_data, test_data = train_test_split(df_orders_final, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Registros totales: {len(df_orders_final)}\")\n",
    "print(f\"Registros para entrenamiento: {len(train_data)}\")\n",
    "print(f\"Registros para evaluaciÃ³n: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b40b109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de entrenamiento creada. Dimensiones: (8618, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Creamos la matriz de utilidad usando solo los datos de entrenamiento\n",
    "df_ratings_train = train_data.groupby(['user_id', 'product_id']).size().reset_index(name='purchase_count')\n",
    "matriz_utilidad = df_ratings_train.pivot(index='user_id', columns='product_id', values='purchase_count')\n",
    "matriz_utilidad = matriz_utilidad.fillna(0)\n",
    "\n",
    "print(f\"Matriz de entrenamiento creada. Dimensiones: {matriz_utilidad.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70df0cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varianza explicada con 20 componentes: 29.53%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# n_components=20 es un buen punto de partida para este tamaÃ±o de catÃ¡logo\n",
    "n_components = 20\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "\n",
    "# Entrenamos el modelo sobre la matriz de utilidad\n",
    "matriz_comprimida = svd.fit_transform(matriz_utilidad)\n",
    "\n",
    "# Varianza explicada: Nos dice quÃ© tanta informaciÃ³n logramos conservar\n",
    "varianza_total = svd.explained_variance_ratio_.sum()\n",
    "print(f\"Varianza explicada con {n_components} componentes: {varianza_total:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45e6b9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Matriz de similitud NLP (Content-Based) lista.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# 1. Limpiamos y preparamos los nombres\n",
    "df_products['ProductName'] = df_products['ProductName'].fillna('')\n",
    "\n",
    "# 2. Vectorizamos los nombres (NLP)\n",
    "tfidf = TfidfVectorizer(stop_words='english') # O 'spanish' si tu data es en espaÃ±ol\n",
    "tfidf_matrix = tfidf.fit_transform(df_products['ProductName'])\n",
    "\n",
    "# 3. Calculamos la similitud de contenido (Coseno)\n",
    "cos_sim_nlp = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# 4. Convertimos a DataFrame para fÃ¡cil acceso\n",
    "df_sim_nlp = pd.DataFrame(\n",
    "    cos_sim_nlp, \n",
    "    index=df_products['product_id'], \n",
    "    columns=df_products['product_id']\n",
    ")\n",
    "\n",
    "print(\"âœ… Matriz de similitud NLP (Content-Based) lista.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8872aedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de similitud entre productos lista.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Extraemos la matriz de productos (transpuesta de los componentes de SVD)\n",
    "# svd.components_ tiene forma (n_components, n_productos)\n",
    "matriz_productos = svd.components_.T\n",
    "\n",
    "# Calculamos la similitud del coseno entre productos\n",
    "similitud_productos = cosine_similarity(matriz_productos)\n",
    "\n",
    "# Lo convertimos a DataFrame para facilitar la bÃºsqueda\n",
    "df_similitud = pd.DataFrame(\n",
    "    similitud_productos, \n",
    "    index=matriz_utilidad.columns, \n",
    "    columns=matriz_utilidad.columns\n",
    ")\n",
    "\n",
    "print(\"Matriz de similitud entre productos lista.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "747676f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_productos(product_id, df_sim, df_products, top_n=3):\n",
    "    if product_id not in df_sim.index:\n",
    "        return []\n",
    "\n",
    "    categoria = df_products.loc[df_products['product_id'] == product_id, 'Category'].values[0]\n",
    "\n",
    "    similares = df_sim[product_id].drop(product_id, errors='ignore').sort_values(ascending=False)\n",
    "\n",
    "    productos_categoria = df_products[df_products['Category'] == categoria]['product_id'].values\n",
    "\n",
    "    similares = similares[similares.index.isin(productos_categoria)]\n",
    "\n",
    "    return similares.head(top_n).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39b50353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Producto base: Onion (Loose) (Cat: Fruits & Vegetables)\n",
      "------------------------------------------------------------\n",
      "1. Tomato - Local (Loose)\n",
      "   ID: P000014 | Cat: Fruits & Vegetables | Similitud: 0.9992\n",
      " https://www.bigbasket.com/media/uploads/p/l/10000203_16-fresho-tomato-local.jpg\n",
      "------------------------------\n",
      "2. Carrot - Orange (Loose)\n",
      "   ID: P000015 | Cat: Fruits & Vegetables | Similitud: 0.9865\n",
      " https://www.bigbasket.com/media/uploads/p/l/10000072_16-fresho-carrot-orange.jpg\n",
      "------------------------------\n",
      "3. Coconut - Large\n",
      "   ID: P000241 | Cat: Fruits & Vegetables | Similitud: 0.9731\n",
      " https://www.bigbasket.com/media/uploads/p/l/10000092_15-fresho-coconut-large.jpg\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "id_a_probar = \"P000001\" \n",
    "ids_recomendados = recomendar_productos(id_a_probar, df_similitud, df_products)\n",
    "\n",
    "nombre_base = df_products.loc[df_products['product_id'] == id_a_probar, 'ProductName'].values[0]\n",
    "cat_base = df_products.loc[df_products['product_id'] == id_a_probar, 'Category'].values[0]\n",
    "\n",
    "print(f\"ðŸ”Ž Producto base: {nombre_base} (Cat: {cat_base})\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if not ids_recomendados:\n",
    "    print(\"No se encontraron recomendaciones en la misma categorÃ­a.\")\n",
    "else:\n",
    "    for i, p_id in enumerate(ids_recomendados, 1):\n",
    "        nombre = df_products.loc[df_products['product_id'] == p_id, 'ProductName'].values[0]\n",
    "        categoria = df_products.loc[df_products['product_id'] == p_id, 'Category'].values[0]\n",
    "        URL = df_products.loc[df_products['product_id'] == p_id, 'Image_Url'].values[0]\n",
    "        \n",
    "        similitud = df_similitud.loc[id_a_probar, p_id]\n",
    "        \n",
    "        print(f\"{i}. {nombre}\")\n",
    "        print(f\"   ID: {p_id} | Cat: {categoria} | Similitud: {similitud:.4f}\\n {URL}\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edb59c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Modelo guardado exitosamente en:\n",
      "c:\\Users\\fredd\\Desktop\\Soy Henry\\ProyectoFinal\\PF-Quantum_Insights\\modelos_entrenados\\modelo_svd_similitud.pkl\n"
     ]
    }
   ],
   "source": [
    "ruta_actual = os.getcwd()\n",
    "\n",
    "# Identificar la carpeta correcta donde se guardarÃ¡n los modelos\n",
    "if os.path.exists(os.path.join(ruta_actual, \"modelos_entrenados\")):\n",
    "    ruta_modelos = os.path.join(ruta_actual, \"modelos_entrenados\")\n",
    "else:\n",
    "    # Buscar la carpeta subiendo un nivel si no estÃ¡ en el actual\n",
    "    ruta_modelos = os.path.join(os.path.dirname(ruta_actual), \"modelos_entrenados\")\n",
    "\n",
    "# Crear la carpeta automÃ¡ticamente si no existe\n",
    "if not os.path.exists(ruta_modelos):\n",
    "    os.makedirs(ruta_modelos)\n",
    "\n",
    "# Construir la ruta completa con el nombre del archivo final\n",
    "archivo_salida = os.path.join(ruta_modelos, \"modelo_svd_similitud.pkl\")\n",
    "\n",
    "# Guardar la tabla de similitudes en un archivo fÃ­sico\n",
    "with open(archivo_salida, 'wb') as f:\n",
    "    pickle.dump(df_similitud, f) \n",
    "\n",
    "print(f\"ðŸ’¾ Modelo guardado exitosamente en:\\n{archivo_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "528a8f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÃ¡lculo de Average Precision (AP) para una consulta\n",
    "def compute_ap(predicciones, objetivos, k):\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(predicciones):\n",
    "        if p in objetivos:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    return score / min(len(objetivos), k)\n",
    "\n",
    "# CÃ¡lculo de NDCG - que tan cerca se esta de un ranking ideal\n",
    "def compute_ndcg(predicciones, objetivos, k):\n",
    "    dcg = 0.0\n",
    "    idcg = 0.0\n",
    "    for i, p in enumerate(predicciones):\n",
    "        if p in objetivos:\n",
    "            dcg += 1.0 / np.log2(i + 2)\n",
    "    num_posibles = min(len(objetivos), k)\n",
    "    for i in range(num_posibles):\n",
    "        idcg += 1.0 / np.log2(i + 2)\n",
    "    \n",
    "    return dcg / idcg if idcg > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bedd4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ðŸ“Š REPORTE FINAL SVD (K=5)\n",
      "==================================================\n",
      "Metrica         | Valor     \n",
      "--------------------------------------------------\n",
      "Precision       | 0.0120\n",
      "Recall          | 0.0546\n",
      "F1-Score        | 0.0195\n",
      "--------------------------------------------------\n",
      "MRR             | 0.0441\n",
      "MAP             | 0.0403\n",
      "NDCG            | 0.0448\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def metricas_svd(df_test, df_sim, df_products, k):\n",
    "    ordenes_test = df_test.groupby('order_id')['product_id'].apply(list)\n",
    "    metrics = {\n",
    "        'Precision': [], 'Recall': [], 'F1': [],\n",
    "        'MRR': [], 'MAP': [], 'NDCG': []\n",
    "    }\n",
    "\n",
    "    for items in ordenes_test:\n",
    "        if len(items) < 2: continue\n",
    "            \n",
    "        for i in range(len(items)):\n",
    "            semilla = items[i]\n",
    "            objetivos = set(items[:i] + items[i+1:])\n",
    "            predicciones = recomendar_productos(semilla, df_sim, df_products, top_n=k)\n",
    "            \n",
    "            if not predicciones: continue\n",
    "\n",
    "            # --- CALCULOS ---\n",
    "            aciertos = len(set(predicciones) & objetivos)\n",
    "            \n",
    "            # Precision & Recall\n",
    "            prec = aciertos / k\n",
    "            rec = aciertos / len(objetivos)\n",
    "            metrics['Precision'].append(prec)\n",
    "            metrics['Recall'].append(rec)\n",
    "            \n",
    "            # F1-Score\n",
    "            if (prec + rec) > 0:\n",
    "                f1 = 2 * (prec * rec) / (prec + rec)\n",
    "            else:\n",
    "                f1 = 0.0\n",
    "            metrics['F1'].append(f1)\n",
    "            \n",
    "            # MRR\n",
    "            rank_score = 0\n",
    "            for rank, p_id in enumerate(predicciones, 1):\n",
    "                if p_id in objetivos:\n",
    "                    rank_score = 1 / rank\n",
    "                    break\n",
    "            metrics['MRR'].append(rank_score)\n",
    "            \n",
    "            # MAP & NDCG\n",
    "            metrics['MAP'].append(compute_ap(predicciones, objetivos, k))\n",
    "            metrics['NDCG'].append(compute_ndcg(predicciones, objetivos, k))\n",
    "\n",
    "    # --- REPORTE ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"ðŸ“Š REPORTE FINAL SVD (K={k})\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"{'Metrica':<15} | {'Valor':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Precision':<15} | {np.mean(metrics['Precision']):.4f}\")\n",
    "    print(f\"{'Recall':<15} | {np.mean(metrics['Recall']):.4f}\")\n",
    "    print(f\"{'F1-Score':<15} | {np.mean(metrics['F1']):.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'MRR':<15} | {np.mean(metrics['MRR']):.4f}\")\n",
    "    print(f\"{'MAP':<15} | {np.mean(metrics['MAP']):.4f}\")\n",
    "    print(f\"{'NDCG':<15} | {np.mean(metrics['NDCG']):.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    name = f\"SVD_K{k}\"\n",
    "    with mlflow.start_run(run_name=name):\n",
    "\n",
    "        # --- ParÃ¡metros ---\n",
    "        mlflow.log_param(\"modelo\", \"SVD\")\n",
    "        mlflow.log_param(\"k\", k)\n",
    "\n",
    "        # --- MÃ©tricas ---\n",
    "        mlflow.log_metric(\"precision\", np.mean(metrics['Precision']))\n",
    "        mlflow.log_metric(\"recall\", np.mean(metrics['Recall']))\n",
    "        mlflow.log_metric(\"f1\", np.mean(metrics['F1']))\n",
    "        mlflow.log_metric(\"mrr\", np.mean(metrics['MRR']))\n",
    "        mlflow.log_metric(\"map\", np.mean(metrics['MAP']))\n",
    "        mlflow.log_metric(\"ndcg\", np.mean(metrics['NDCG']))\n",
    "    return metrics\n",
    "\n",
    "resultados_svd = metricas_svd(test_data, df_similitud, df_products, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
